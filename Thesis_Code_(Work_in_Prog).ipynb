{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#DRAFT 1 DOESNT WORK\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense\n",
        "class SimplexAttention(Layer):\n",
        "    def __init__(self, units):\n",
        "        super(SimplexAttention, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W_q = Dense(self.units)\n",
        "        self.W_k = Dense(self.units)\n",
        "        self.W_v = Dense(self.units)\n",
        "\n",
        "    def call(self, query, key, value, mask):\n",
        "        # Linear layers\n",
        "        query = self.W_q(query)\n",
        "        key = self.W_k(key)\n",
        "        value = self.W_v(value)\n",
        "\n",
        "        # Scale dot-product attention\n",
        "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "        # Apply mask\n",
        "        if mask is not None:\n",
        "            logits += (mask * -1e9)\n",
        "\n",
        "        # Softmax\n",
        "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "        output = tf.matmul(attention_weights, value)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class DuplexAttention(SimplexAttention):\n",
        "    def call(self, query, key, value, mask):\n",
        "        # Apply Simplex Attention\n",
        "        simplex_output = super().call(query, key, value, mask)\n",
        "\n",
        "        # Apply Duplex Attention (considering future states)\n",
        "        future_mask = None  # Not applying the mask for future tokens\n",
        "        duplex_output = super().call(query, key, value, future_mask)\n",
        "\n",
        "        # Combine simplex and duplex outputs\n",
        "        output = (simplex_output + duplex_output) / 2\n",
        "\n",
        "        return output\n",
        "\n",
        "class BipartiteTransformer(Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BipartiteTransformer, self).__init__()\n",
        "        self.simplex_attention = SimplexAttention(units)\n",
        "        self.duplex_attention = DuplexAttention(units)\n",
        "        self.linear = Dense(units)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        simplex_output = self.simplex_attention(inputs, inputs, inputs, mask)\n",
        "        duplex_output = self.duplex_attention(inputs, inputs, inputs, mask)\n",
        "\n",
        "        # Combine the outputs\n",
        "        combined_output = tf.concat([simplex_output, duplex_output], axis=-1)\n",
        "\n",
        "        # Pass through a linear layer\n",
        "        output = self.linear(combined_output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "2qC_m54Xo6Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWzhfPuwnxwe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#DRAFT 2\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = tf.range(position, dtype=tf.float32)[:, tf.newaxis] / tf.math.pow(10000, (tf.range(d_model, dtype=tf.float32)[tf.newaxis, :] // 2) * 2 / d_model) #wtf i just vomited pure garbage\n",
        "    angle_rads[:, 0::2] = tf.math.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = tf.math.cos(angle_rads[:, 1::2])\n",
        "    return angle_rads[tf.newaxis, ...]\n",
        "\n",
        "class SimplexAttention(layers.Layer):\n",
        "    def __init__(self, d_model):\n",
        "        super(SimplexAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.W_q = layers.Dense(d_model)\n",
        "        self.W_k = layers.Dense(d_model)\n",
        "        self.W_v = layers.Dense(d_model)\n",
        "\n",
        "    def call(self, query, key, value):\n",
        "        query = self.W_q(query)\n",
        "        key = self.W_k(key)\n",
        "        value = self.W_v(value)\n",
        "\n",
        "        scores = tf.matmul(query, key, transpose_b=True) / tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        attention_weights = tf.nn.softmax(scores, axis=-1)\n",
        "\n",
        "        output = tf.matmul(attention_weights, value)\n",
        "        return output\n",
        "\n",
        "class DuplexAttention(layers.Layer):\n",
        "    def __init__(self, d_model):\n",
        "        super(DuplexAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.W_q = layers.Dense(d_model)\n",
        "        self.W_k = layers.Dense(d_model)\n",
        "        self.W_v = layers.Dense(d_model)\n",
        "\n",
        "    def call(self, query, key, value):\n",
        "        query = self.W_q(query)\n",
        "        key = self.W_k(key)\n",
        "        value = self.W_v(value)\n",
        "\n",
        "        # Adding positional encoding\n",
        "        pos_encoding = positional_encoding(key.shape[1], self.d_model)\n",
        "        key += pos_encoding\n",
        "        value += pos_encoding\n",
        "\n",
        "        scores = tf.matmul(query, key, transpose_b=True) / tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        attention_weights = tf.nn.softmax(scores, axis=-1)\n",
        "\n",
        "        future_output = tf.matmul(attention_weights, value)\n",
        "\n",
        "        return future_output\n",
        "\"\"\"\n",
        "class BipartiteTransformer(layers.Layer):\n",
        "    def __init__(self, d_model):\n",
        "        super(BipartiteTransformer, self).__init__()\n",
        "        self.simplex_attention = SimplexAttention(d_model)\n",
        "        self.duplex_attention = DuplexAttention(d_model)\n",
        "        self.feed_forward = layers.Dense(d_model)\n",
        "\n",
        "    def call(self, query, key, value):\n",
        "        simplex_output = self.simplex_attention(query, key, value)\n",
        "        duplex_output = self.duplex_attention(query, key, value)\n",
        "\n",
        "        # Merge the Simplex and Duplex outputs.\n",
        "        merged_output = tf.concat([simplex_output, duplex_output], axis=-1)\n",
        "\n",
        "        output = self.feed_forward(merged_output)\n",
        "        return output\n",
        "\n",
        "\"\"\"\n",
        "input_data = tf.random.normal((32, 50, 128))  # (batch_size, sequence_length, d_model)\n",
        "bipartite_transformer = BipartiteTransformer(d_model=128)\n",
        "output = bipartite_transformer(input_data, input_data, input_data)\n",
        "\n",
        "print(\"Bipartite Transformer Output Shape:\", output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_RDNN(input_shape=(50, 10)):\n",
        "    input_layer = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.LSTM(128, return_sequences=True)(input_layer)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.LSTM(64, return_sequences=True)(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    output_layer = layers.Dense(input_shape[1])(x)  # Output shape is the same as input shape on the last dimension (10)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "_zI7uOPxvepC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_mha_wgan_generator():\n",
        "    input_layer = layers.Input(shape=(5, 256, 256, 1))  # 5 images of shape 256x256x1\n",
        "\n",
        "    x = layers.TimeDistributed(layers.Flatten())(input_layer)\n",
        "\n",
        "    x = layers.LSTM(512, return_sequences=True)(x)\n",
        "\n",
        "    # Multi-Head Attention Layer\n",
        "    mha_layer = layers.MultiHeadAttention(num_heads=4, key_dim=512)\n",
        "    x = mha_layer(x, x)\n",
        "\n",
        "    x = layers.LSTM(1024, return_sequences=True)(x)\n",
        "\n",
        "    x = layers.Reshape((5, 16, 16, 16))(x)\n",
        "\n",
        "    x = layers.Conv3DTranspose(128, (3, 3, 3), strides=(1, 2, 2), padding='same', activation='relu')(x)\n",
        "\n",
        "    x = layers.Conv3DTranspose(64, (3, 3, 3), strides=(1, 2, 2), padding='same', activation='relu')(x)\n",
        "\n",
        "    output_images = layers.Conv3DTranspose(1, (3, 3, 3), strides=(1, 2, 2), padding='same', activation='tanh')(x)\n",
        "\n",
        "    return models.Model(inputs=input_layer, outputs=output_images)\n",
        "\n",
        "generator = build_mha_wgan_generator()\n",
        "generator.summary()\n",
        "\n",
        "def build_mha_wgan_discriminator():\n",
        "    input_layer = layers.Input(shape=(5, 256, 256, 1))  # 5 images of shape 256x256x1\n",
        "\n",
        "    x = layers.Conv3D(64, (3, 3, 3), strides=(1, 2, 2), padding='same', activation='relu')(input_layer)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    # Multi-Head Attention Layer\n",
        "    mha_layer = layers.MultiHeadAttention(num_heads=4, key_dim=512)\n",
        "    x = mha_layer(x, x)\n",
        "\n",
        "    x = layers.Dense(1024, activation='relu')(x)\n",
        "\n",
        "    # Using linear activation for Wasserstein loss\n",
        "    output_layer = layers.Dense(1)(x)\n",
        "\n",
        "    return models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "discriminator = build_mha_wgan_discriminator()\n",
        "discriminator.summary()\n"
      ],
      "metadata": {
        "id": "-NKZUNDX0O8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# idk this is a janky model so im trying everything\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "class BipartiteTransformer(layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BipartiteTransformer, self).__init__()\n",
        "        self.simplex_attention = SimplexAttention()\n",
        "        self.duplex_attention = DuplexAttention()\n",
        "\n",
        "    def call(self, x):\n",
        "        simplex_out = self.simplex_attention(x, x, x)  # Query, Key, Value\n",
        "        duplex_out = self.duplex_attention(x, x, x)  # Query, Key, Value\n",
        "        return layers.Add()([simplex_out, duplex_out])\n",
        "'''\n",
        "def build_cGATN_generator(mha_wgan_gen, rdnn):\n",
        "    # Process image output from MHA WGAN\n",
        "    image_processed = layers.Conv2D(64, (3,3), padding='same', activation='relu')(mha_wgan_gen.output)\n",
        "    image_processed = layers.MaxPooling2D((2, 2))(image_processed)\n",
        "    image_processed = layers.Flatten()(image_processed)\n",
        "\n",
        "    # Process numerical data output from RDNN\n",
        "    num_processed = layers.Dense(50, activation='relu')(rdnn.output)\n",
        "\n",
        "    # Merge processed image and numerical data\n",
        "    merged = layers.Concatenate()([image_processed, num_processed])\n",
        "\n",
        "    # Processing fused data with LSTM\n",
        "    lstm_out = layers.LSTM(50, return_sequences=True)(layers.Reshape((-1, 1))(merged))  # Adding sequence dimension\n",
        "    lstm_out = layers.LSTM(50)(lstm_out)\n",
        "\n",
        "    # Integrating Bipartite Transformer\n",
        "    transformer = BipartiteTransformer(units=50)\n",
        "    transformer_out = transformer(tf.expand_dims(lstm_out, axis=1))  # Adding time dimension\n",
        "\n",
        "\n",
        "    x = layers.Dense(256, activation=\"relu\")(transformer_out)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Reshape((16, 16, 1))(x)\n",
        "    x = layers.Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    output_image = layers.Conv2DTranspose(1, (3,3), strides=(2,2), padding='same', activation='tanh')(x)\n",
        "\n",
        "    return models.Model(inputs=[mha_wgan_gen.input, rdnn.input], outputs=output_image)\n",
        "'''\n",
        "\n",
        "# Assuming the output shape from RDNN is (50,10)\n",
        "# Assuming the output shape from MHA WGAN is (5, 256, 256, 1)\n",
        "\n",
        "def build_cGATN_generator(mha_wgan_gen, rdnn):\n",
        "    # Process sequence of 5 images output from MHA WGAN\n",
        "    image_processed = layers.TimeDistributed(layers.Conv2D(64, (3,3), padding='same', activation='relu'))(mha_wgan_gen.output)\n",
        "    image_processed = layers.TimeDistributed(layers.MaxPooling2D((2, 2)))(image_processed)\n",
        "    image_processed = layers.TimeDistributed(layers.Flatten())(image_processed)\n",
        "\n",
        "    # Process numerical data output from RDNN\n",
        "    num_processed = layers.Dense(50, activation='relu')(rdnn.output)\n",
        "\n",
        "    # Expand dimensions to merge with images\n",
        "    num_processed = layers.RepeatVector(5)(num_processed)\n",
        "\n",
        "    # Merge processed image and numerical data\n",
        "    merged = layers.Concatenate(axis=-1)([image_processed, num_processed])\n",
        "\n",
        "    # Processing fused data with LSTM\n",
        "    lstm_out = layers.LSTM(50, return_sequences=True)(merged)\n",
        "    lstm_out = layers.LSTM(50, return_sequences=True)(lstm_out)\n",
        "\n",
        "    # Integrating Bipartite Transformer\n",
        "    transformer = BipartiteTransformer(units=100) #50 * 2\n",
        "    transformer_out = transformer(lstm_out)\n",
        "\n",
        "    # Completing the generator architecture to produce an image as output\n",
        "    x = layers.TimeDistributed(layers.Dense(256, activation=\"relu\"))(transformer_out)\n",
        "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "    x = layers.TimeDistributed(layers.Reshape((16, 16, 1)))(x)\n",
        "    x = layers.TimeDistributed(layers.Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu'))(x)\n",
        "    x = layers.TimeDistributed(layers.BatchNormalization())(x)\n",
        "    output_image = layers.TimeDistributed(layers.Conv2DTranspose(1, (3,3), strides=(2,2), padding='same', activation='tanh'))(x)\n",
        "\n",
        "    return models.Model(inputs=[mha_wgan_gen.input, rdnn.input], outputs=output_image)\n",
        "\n",
        "\n",
        "mha_wgan_gen = build_mha_wgan_generator()\n",
        "rdnn = build_RDNN()\n",
        "\n",
        "# Now build the cGATN generator\n",
        "cGATN_gen = build_cGATN_generator(mha_wgan_gen, rdnn)\n",
        "cGATN_gen.summary()\n",
        "\n",
        "\n",
        "def build_cGATN_discriminator():\n",
        "    radar_input = layers.Input(shape=(64, 64, 1))\n",
        "    num_weather_data_input = layers.Input(shape=(50,))\n",
        "\n",
        "    # Fuse numerical weather data with radar imagery\n",
        "    x = layers.Flatten()(radar_input)\n",
        "    merged = layers.Concatenate()([x, num_weather_data_input])\n",
        "\n",
        "    # Building the discriminator\n",
        "    x = layers.Dense(256, activation=\"relu\")(merged)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return models.Model(inputs=[radar_input, num_weather_data_input], outputs=output_layer)\n",
        "\n"
      ],
      "metadata": {
        "id": "eIthEW0DstI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STILL FLESHING THIS PART OUT\n",
        "import tensorflow as tf\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "learning_rate = 0.00005\n",
        "\n",
        "# Build models\n",
        "mha_wgan_gen, mha_wgan_disc = build_MHA_WGAN()\n",
        "rdnn = build_RDNN()\n",
        "cGATN_gen, cGATN_disc = build_cGATN_generator(mha_wgan_gen, rdnn), build_cGATN_discriminator()\n",
        "\n",
        "# Compile models\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "# Custom Wasserstein loss function\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return -tf.reduce_mean(y_true * y_pred)\n",
        "\n",
        "mha_wgan_gen.compile(optimizer=optimizer, loss=wasserstein_loss)\n",
        "mha_wgan_disc.compile(optimizer=optimizer, loss=wasserstein_loss)\n",
        "rdnn.compile(optimizer=optimizer, loss='mse')  # Mean squared error, or another suitable loss\n",
        "cGATN_gen.compile(optimizer=optimizer, loss=wasserstein_loss)\n",
        "cGATN_disc.compile(optimizer=optimizer, loss=wasserstein_loss)\n",
        "\n",
        "\n",
        "# X_train_images, X_train_numerical_data and y_train_images\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for (X_images, X_numerical, y_images) in zip(X_train_images, X_train_numerical_data, y_train_images):\n",
        "\n",
        "        # Labels for real and fake data\n",
        "        real_labels = -tf.ones((batch_size, 1))\n",
        "        fake_labels = tf.ones((batch_size, 1))\n",
        "\n",
        "        # Train MHA WGAN\n",
        "        with tf.GradientTape() as tape:\n",
        "            generated_images = mha_wgan_gen(X_images)\n",
        "            real_output = mha_wgan_disc(y_images)\n",
        "            fake_output = mha_wgan_disc(generated_images)\n",
        "            disc_loss = wasserstein_loss(real_labels, real_output) + wasserstein_loss(fake_labels, fake_output)\n",
        "\n",
        "        grads = tape.gradient(disc_loss, mha_wgan_disc.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, mha_wgan_disc.trainable_variables))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            generated_images = mha_wgan_gen(X_images)\n",
        "            fake_output = mha_wgan_disc(generated_images)\n",
        "            gen_loss = wasserstein_loss(real_labels, fake_output)\n",
        "\n",
        "        grads = tape.gradient(gen_loss, mha_wgan_gen.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, mha_wgan_gen.trainable_variables))\n",
        "\n",
        "        # Train RDNN\n",
        "        rdnn_loss = rdnn.train_on_batch(X_numerical, y_numerical)  # Assuming y_numerical is the target\n",
        "\n",
        "        # Train cGATN\n",
        "        refined_images = cGATN_gen([generated_images, rdnn_output])\n",
        "        cGATN_disc_loss = cGATN_disc.train_on_batch([refined_images, rdnn_output], real_labels)\n",
        "        cGATN_gen_loss = cGATN_gen.train_on_batch([refined_images, rdnn_output], fake_labels)\n",
        "\n",
        "        print(f\"Epoch: {epoch}, MHA WGAN Discriminator Loss: {disc_loss}, MHA WGAN Generator Loss: {gen_loss}\")\n",
        "        print(f\"Epoch: {epoch}, cGATN Discriminator Loss: {cGATN_disc_loss}, cGATN Generator Loss: {cGATN_gen_loss}, RDNN Loss: {rdnn_loss}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "0KGFBIID0hKt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
